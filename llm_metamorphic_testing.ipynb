{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing LLM Query Outputs with Cosine Similarity\n",
    "\n",
    "In this notebook, we demonstrate a metamorphic testing approach for LLM-based features. Instead of using hard-coding your expected outputs, we test whether the outputs from similar or contrasting queries confirm the expected relationships by measuring their cosine similarity.\n",
    "\n",
    "For example, if two queries with the same intent (but expressed differently) are issued, we expect their outputs to be semantically similar. Conversely, if a query is rephrased to flip its sentiment, we expect a low or even negative cosine similarity between the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sagar/Code/cosine_similarity_metamorphic_testing/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# We are using one of the very popular small yet efficient Transformer model for computing embeddings for our texts. \n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def get_embedding(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns the embedding vector for the given text.\n",
    "    \"\"\"\n",
    "    embedding = model.encode([text])\n",
    "    return embedding\n",
    "\n",
    "def compute_cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors. Returns a value between -1 and 1.\n",
    "    \"\"\"\n",
    "    return cosine_similarity(vec1, vec2)[0][0]\n",
    "\n",
    "def simulate_llm_output(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulates an LLM query response. In a real-world scenario, this function would call an LLM API.\n",
    "    \"\"\"\n",
    "    # For demonstration, we return a predefined response based on the query content\n",
    "    if \"drawbacks\" in query or \"negative aspects\" in query:\n",
    "        return \"Eating outside can expose you to unpredictable weather and risks of foodborne illnesses.\"\n",
    "    elif \"benefits\" in query or \"positive aspects\" in query:\n",
    "        return \"Dining outdoors can improve your mood and offer a refreshing change from routine indoor meals.\"\n",
    "    else:\n",
    "        return \"The experience of outdoor dining depends on various factors including weather and food quality.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define queries with metamorphic relations\n",
    "query_similar_1 = \"What are the drawbacks of eating outside?\"\n",
    "query_similar_2 = \"What negative aspects come with outdoor dining?\"\n",
    "\n",
    "query_opposite_1 = \"What are the drawbacks of eating outside?\"\n",
    "query_opposite_2 = \"What are the benefits of eating outside?\"\n",
    "\n",
    "# Simulate LLM outputs for the queries\n",
    "output_similar_1 = simulate_llm_output(query_similar_1)\n",
    "output_similar_2 = simulate_llm_output(query_similar_2)\n",
    "\n",
    "output_opposite_1 = simulate_llm_output(query_opposite_1)\n",
    "output_opposite_2 = simulate_llm_output(query_opposite_2)\n",
    "\n",
    "# Obtain embeddings for the simulated outputs\n",
    "embedding_similar_1 = get_embedding(output_similar_1)\n",
    "embedding_similar_2 = get_embedding(output_similar_2)\n",
    "\n",
    "embedding_opposite_1 = get_embedding(output_opposite_1)\n",
    "embedding_opposite_2 = get_embedding(output_opposite_2)\n",
    "\n",
    "# Compute cosine similarities\n",
    "similarity_similar = compute_cosine_similarity(embedding_similar_1, embedding_similar_2)\n",
    "similarity_opposite = compute_cosine_similarity(embedding_opposite_1, embedding_opposite_2)\n",
    "\n",
    "print(f\"Cosine Similarity for similar queries (drawbacks): {similarity_similar:.3f}\")\n",
    "print(f\"Cosine Similarity for opposite queries (drawbacks vs benefits): {similarity_opposite:.3f}\")\n",
    "\n",
    "def interpret_similarity(sim: float) -> str:\n",
    "    \"\"\"\n",
    "    Provides an interpretation of the cosine similarity value.\n",
    "    \"\"\"\n",
    "    if sim >= 0.7:\n",
    "        return \"The outputs are highly similar (expected for similar queries).\"\n",
    "    elif sim <= -0.7:\n",
    "        return \"The outputs are highly opposite (expected for contrasting queries).\"\n",
    "    elif -0.3 < sim < 0.3:\n",
    "        return \"The outputs are largely unrelated.\"\n",
    "    else:\n",
    "        return \"The outputs show moderate similarity/difference.\"\n",
    "\n",
    "print(\"Interpretation for similar queries:\", interpret_similarity(similarity_similar))\n",
    "print(\"Interpretation for opposite queries:\", interpret_similarity(similarity_opposite))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook illustrates a metamorphic testing approach for LLM query outputs using cosine similarity. By simulating LLM responses for different queries and comparing their semantic similarity, we can verify whether the model's outputs adhere to the expected relationships-without relying on fixed, deterministic expected outputs.\n",
    "\n",
    "Such an approach is especially useful when working with non-deterministic LLM outputs where traditional testing methods may fall short."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
